---
title: "SKATER validation"
author: "Jeffrey Wu"
date: "2023-05-23"
output: pdf_document
---

Starting toy data: 

```{r}
library(MASS)

x1 = CA_newdata$EDUC_college
x2 = CA_newdata$Unemployment_Rate
N = length(x1)

sigma = 1
alpha = 0.5

Ksigma = matrix(data = NA,nrow = N, ncol = N)

for (i in 1:N){
  for (j in 1:N){
    Ksigma[i,j] = exp(-((x1[i]-x1[j])^2 + (x2[i]-x2[j])^2) / (2*sigma^2))
    }
}

#Set mean 0 generally
lambda0 = 1
mu0 = 1

#Generate toy hospitalization counts (time series of 100 for each county )
Hospitalizations = matrix(0,nrow = 100,ncol = 58)

for (i in 1:100){
  lambdas = lambda0*mu0*exp(mvrnorm(n=1,rep(0,N),Ksigma))
  for (j in 1:N){
    Hospitalizations[i,j] = rgenpois(1,lambda1 = lambdas[j],lambda2 = alpha)
  }
}

hosp_standardized = Hospitalizations

for (i in 1:58){
  means = colMeans(Hospitalizations)
  hosp_standardized[,i] = hosp_standardized[,i] - means[i]
}


#Hospitalizations = data.frame(Hospitalizations)
#toydata1 = cbind(CA_newdata,Hospitalizations)

#Calculate sample covariance matrix (Sigma1) -> make sure it's positive def
Sigma1 = (t(hosp_standardized) %*% hosp_standardized) / 99

library(reshape2)
melted_cormat <- melt(Sigma1)
head(melted_cormat)

library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()
```

```{r}
#Introduce sparsity into precision matrix (inv of Sigma1)
blocks58 = blocksplit(Sigma1)
Sigma1.2 = CEblock(blocks58)

View(Sigma1.2[[2]])
det(Sigma1.2[[2]]) #check det of prec matrix 
det(Sigma1.2[[1]]) #check det of cov matrix 
isSymmetric(Sigma1.2[[2]])

#Heatmap of sparsified prec matrix (inverse of Sigma1.2)
library(reshape2)
melted_cormat <- melt(Sigma1.2[[2]])
head(melted_cormat)

library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()

Sigma2 = Sigma1.2[[1]]
Prec2 = Sigma1.2[[2]]
```


```{r}
#Introduce a little more sparsity into Prec2 (in blocks 2 and 4)
blocks58.prec2 = blocksplit(Prec2)

block2 = blocks58.prec2[[2]]

prop0 = 15/361
sparsity = sample(c(0,1),size = 361,prob = c(prop0,1-prop0),replace=T)
sparsity = matrix(sparsity,nrow(block2),ncol(block2))

block2.1 = block2*sparsity
block4.1 = t(block2.1)
det(block2.1)

#Heatmap of sparsified block2
library(reshape2)
melted_cormat <- melt(block2.1)
head(melted_cormat)

library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()

blocks58.prec2[[2]] = block2.1
blocks58.prec2[[4]] = block4.1


rowsPrec2.1 = cbind(blocks58.prec2[[1]],blocks58.prec2[[2]],blocks58.prec2[[3]])
rowsPrec2.2 = cbind(blocks58.prec2[[4]],blocks58.prec2[[5]],blocks58.prec2[[6]])
rowsPrec2.3 = cbind(blocks58.prec2[[7]],blocks58.prec2[[8]],blocks58.prec2[[9]])

Prec2.1 = rbind(rowsPrec2.1,rowsPrec2.2,rowsPrec2.3)

#Heatmap of sparsified prec matrix (inverse of Sigma2.1)
library(reshape2)
melted_cormat <- melt(Prec2)
head(melted_cormat)

library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()

#Heatmap of extra sparsified prec matrix (add more 0s in blocks 2 and 4)
library(reshape2)
melted_cormat <- melt(Prec2.1)
head(melted_cormat)

library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()

Sigma2.1 = solve(Prec2.1)
det(Sigma2.1)
```


Generate new toy data with Sigma2

```{r}
set.seed(25)
sigma = 1
alpha = 0.5

#Covariance eq from graph regression paper? 
#Sigma = kronecker(Ksigma,adj^2)

#Set mean 0 generally
lambda0 = 1
mu0 = 1

lambdas = lambda0*mu0*exp(mvrnorm(n=1,rep(0,58),Sigma2.1))
Hospitalizations = rep(0,58)

for (i in 1:N){
  Hospitalizations[i] = rgenpois(1,lambda1 = lambdas[j],lambda2 = alpha)
}

# Hospitalizations = matrix(0,nrow = 58,ncol = 10)
# 
# for (i in 1:10){
#   vec = rep(0,58)
#   for (j in 1:N){
#     vec[j] = rgenpois(1,lambda1 = lambdas[j],lambda2 = alpha)
#   }
#   Hospitalizations[,i] = vec
# }

```



Run SKATER on newly generated hospitalizations data: 

SKATER clustering: 

```{r}
###Setting up SPDF for CA counties 
CA_sf = st_read(getwd(),"CA_Counties_TIGER2016")
CA_spdf = as_Spatial(CA_sf)

hosp_scaled = scale(Hospitalizations)
covariates_scale = data.frame(hosp_scaled)

CA_spdf@data = covariates_scale

#Identify neighborhood list for counties 
CA_nb = poly2nb(CA_spdf)

# plot(CA_spdf, main = "With queen")
# plot(CA_nb, coords = coordinates(CA_spdf), col="blue", add = TRUE)

#Calculate edge costs (dissimilarity matrix) based on Euclidean distance 
costs <- nbcosts(CA_nb, data = covariates_scale)

###Get adjacency matrix using nb2mat() (SEPARATE STEP FOR INLA)
#adj = nb2mat(CA_nb,style = "B")

#Transform edge costs to spatial weights 
ct_w <- nb2listw(CA_nb,costs,style="B")

#Create minimum spanning tree 
ct_mst <- mstree(ct_w)

#Run SKATER algorithm to get 3 contiguous clusters (cluster idx is in order of CA_sf)
clus3 <- skater(edges = ct_mst[,1:2], data = covariates_scale, ncuts = 2)

#Plot clustered CA
plot((CA_sf %>% mutate(clus = clus3$groups))['clus'], main = "3 cluster from SKATER")

table(clus3$groups)
```


```{r}
#Hardcode covariance matrix 
Sigma3 = matrix(NA,nrow = 58,ncol=58)
for (i in 1:58){
  for (j in 1:58){
    if (i == j){
      Sigma3[i,j] = 1
    }
    
    else if (clus5groups[i] != clus5groups[j]){
      Sigma3[i,j] = 0
    }
    
    else if(clus5groups[i] == clus5groups[j]){
      Sigma3[i,j] = 0.5
    }
  }
}

head(Sigma3)  
```



