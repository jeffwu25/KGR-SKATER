---
title: "Important Plots"
author: "Jeffrey Wu"
date: "2023-08-22"
output: pdf_document
---

```{r,include=FALSE}
library(dplyr) 
library(tidyverse)
library(lubridate)
library(stringr)
library(zoo)
library(ggplot2)
library(urbnmapr)
library(devtools)
library(readxl)
library(spdep)
library(sp)
library(INLA)
library(HMMpa)
library(invgamma)
library(maps)
library(ggmap)
library(colorspace)

county_map <- map_data("county", region = "california")
```


## HEATMAPS FOR DEPRIVATION SCORE FOR EACH YEAR

```{r}
plot_list = list()
j=1

for (y in 2014:2019){
  SDI_data = soa_joint %>% filter(Year == y)

  lat0=min(SDI_data$lat)
  lat1=max(SDI_data$lat)
  label = sprintf("SDI Score %s",y)
  
  heatmap = ggplot() + geom_polygon(data = SDI_data, aes(x = long, y = lat, group = group, fill = Score), 
               color = "black") +
  coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
  theme_void() +
  labs(title = "",fill = label) +
  scale_fill_gradient(low = "yellow", high = "red") + 
  theme(
    legend.text  = element_text(size = 14),  # legend labels
    legend.title = element_text(size = 16)   # legend title
  )
  
  # heatmap = SDI_data %>%
  #   ggplot(aes(long, lat, group = group, fill = Score)) +
  #   scale_fill_gradient(low = "yellow", high = "red", na.value = "grey90",limits=c(65, 185))+  ###here limits set an upper and lower bound
  #   geom_polygon(col = "black") +
  #   coord_map(projection = "albers", lat0 = lat0, lat1 = lat1) +  ###lat0 and lat1 are how wide you should draw
  #   labs(fill = expression("Deprivation Score")) +
  #   ggtitle(sprintf("Deprivation Score by County in %1.0f",y))+
  #   xlab("lon") +ylab("lat" )  
  
  print(heatmap)
  plot_list[[j]] = heatmap
  j=j+1
}

combined = wrap_plots(plotlist = plot_list, ncol = 2)
combined

# Save one combined figure
ggsave(
  filename = paste0("sdi_combined_plot.png"),
  plot = combined,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
  width = 8,
  height = 10,
  dpi = 300
)
```


## HEATMAPS FOR TOTAL MORTALITY FOR EACH YEAR: 

```{r,message=FALSE,eval=FALSE}
years = 2014:2019
for (i in years){
  totaldeaths = total.respmortality %>% group_by(County,Year) %>% summarise(Total_Deaths = sum(Total_Deaths)) %>% filter(Year == i)
  totaldeaths$County <- tolower(totaldeaths$County)

  #Plot onto a heatmap
  
  # Merge county map data with the dataset containing deaths
  county_map_totaldeaths <- merge(county_map, totaldeaths, by.x = "subregion", by.y = "County")
  
  # Plot the heatmap using ggplot2
  heatmap_plot <- ggplot(county_map_totaldeaths, aes(x = long, y = lat, group = group)) +
    geom_polygon(aes(fill = Total_Deaths), color = "black", size = 0.2) +  # Heatmap fill with     county lines
    coord_fixed() +
    labs(title = paste0("Total Respiratory Related Deaths in ", i),
         fill = "Deaths") +
    scale_fill_gradient(low = "blue", high = "red") +
    theme_void()
  
  
  # Display the heatmap plot
  print(heatmap_plot)  
}
```


HEATMAP FOR TOTAL MORTALITY PER 100,000 FOR 2019: 

```{r}
totaldeaths = rep(0,58)

for (i in 1:58){
  # total = mortality3 %>% group_by(County_of_Death) %>% filter(Year_of_Death == 2019) %>% filter(County_of_Death == counties[i]) %>% summarise(Total_Deaths = sum(Total_Deaths))
  
  total = mortality3 %>% filter(Year_of_Death == 2014, Month_of_Death == 12, County_of_Death == counties[i]) %>% summarise(Total_Deaths = sum(Total_Deaths))
  
  totaldeaths[i] = total$Total_Deaths
}

totaldeaths = data.frame(totaldeaths)
totaldeaths = cbind(totaldeaths,counties)
colnames(totaldeaths) = c("Total_Deaths","County")

#2010-2019 population data for CA 
USpops = read.csv("CA_census_pops1019.csv")
CApops = USpops %>% filter(STNAME == "California") %>% select(CTYNAME,POPESTIMATE2019)
CApops = CApops[-1,]

#Scale total deaths to become rate: per 100,000
totaldeaths$Total_Deaths = totaldeaths$Total_Deaths*100000/CApops$POPESTIMATE2019
totaldeaths$County <- tolower(totaldeaths$County)

#Plot onto a heatmap
# Merge county map data with the dataset containing deaths
county_map_totaldeaths <- merge(county_map, totaldeaths, by.x = "subregion", by.y = "County")

# # Plot the heatmap using ggplot2

# heatmap_plot <- ggplot(county_map_totaldeaths, aes(x = long, y = lat, group = group)) +
#   geom_polygon(aes(fill = Total_Deaths), color = "black", size = 0.2) +  # Heatmap fill with county lines
#   coord_fixed() +
#   labs(title = "",
#        fill = "Deaths (per 100,000 people) 2014") +
#   scale_fill_gradient(low = "yellow", high = "red",limits = c(0,150)) +
#   theme_minimal()
# 
# 
# # Display the heatmap plot
# print(heatmap_plot)  


death_plot = ggplot() + geom_polygon(data = county_map_totaldeaths, aes(x = long, y = lat, group = group, fill = Total_Deaths), 
             color = "black") + 
  coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
  theme_void() +labs(title = "",fill = expression("Deaths (per 100,000) Dec 2014")) + 
  scale_fill_gradient(low = "yellow", high = "red",limits = c(0,10)) + 
  theme(
    legend.text  = element_text(size = 14),  # legend labels
    legend.title = element_text(size = 16)   # legend title
  )

print(death_plot)
```


```{r}
tracker = 1
plot_list = list()
months = c("July","Aug","Sept","Oct","Nov","Dec")

for (j in 7:12){
  totaldeaths = rep(0,58)

  for (i in 1:58){
    # total = mortality3 %>% group_by(County_of_Death) %>% filter(Year_of_Death == 2019) %>% filter(County_of_Death == counties[i]) %>% summarise(Total_Deaths = sum(Total_Deaths))
    
    total = mortality3 %>% filter(Year_of_Death == 2014, Month_of_Death == j, County_of_Death == counties[i]) %>% summarise(Total_Deaths = sum(Total_Deaths))
    
    totaldeaths[i] = total$Total_Deaths
  }
  
  totaldeaths = data.frame(totaldeaths)
  totaldeaths = cbind(totaldeaths,counties)
  colnames(totaldeaths) = c("Total_Deaths","County")
  
  #2010-2019 population data for CA 
  USpops = read.csv("CA_census_pops1019.csv")
  CApops = USpops %>% filter(STNAME == "California") %>% select(CTYNAME,POPESTIMATE2019)
  CApops = CApops[-1,]
  
  #Scale total deaths to become rate: per 100,000
  totaldeaths$Total_Deaths = totaldeaths$Total_Deaths*100000/CApops$POPESTIMATE2019
  totaldeaths$County <- tolower(totaldeaths$County)
  
  #Plot onto a heatmap
  # Merge county map data with the dataset containing deaths
  county_map_totaldeaths <- merge(county_map, totaldeaths, by.x = "subregion", by.y = "County")
  
  # # Plot the heatmap using ggplot2
  
  # heatmap_plot <- ggplot(county_map_totaldeaths, aes(x = long, y = lat, group = group)) +
  #   geom_polygon(aes(fill = Total_Deaths), color = "black", size = 0.2) +  # Heatmap fill with county lines
  #   coord_fixed() +
  #   labs(title = "",
  #        fill = "Deaths (per 100,000 people) 2014") +
  #   scale_fill_gradient(low = "yellow", high = "red",limits = c(0,150)) +
  #   theme_minimal()
  # 
  # 
  # # Display the heatmap plot
  # print(heatmap_plot)  
  
  label = sprintf("Deaths (per 100,000) %s 2014",months[tracker])
  
  
  death_plot = ggplot() + geom_polygon(data = county_map_totaldeaths, aes(x = long, y = lat, group = group, fill = Total_Deaths), 
               color = "black") + 
    coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
    theme_void() +labs(title = "",fill = label) + 
    scale_fill_gradient(low = "yellow", high = "red",limits = c(0,25)) + 
    theme(
      legend.text  = element_text(size = 14),  # legend labels
      legend.title = element_text(size = 16)   # legend title
    )
  
  print(death_plot)
  plot_list[[tracker]] = death_plot
  tracker = tracker+1
}

combined = wrap_plots(plotlist = plot_list, ncol = 2)
combined

# Save one combined figure
ggsave(
  filename = paste0("deathrate_combined_plot.png"),
  plot = combined,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
  width = 12,
  height = 15,
  dpi = 300
)
```


## HEATMAPS OF AQI LEVELS WITH STATION LOCATIONS MARKED

Get average AQI value for each county for Sept 2014: 

```{r}
Sept_avgs = c()

for (i in 1:58){ 
  #Filter by county
  county14 = final_data14 %>% filter(stringr::str_starts(rownames(final_data14), counties[i])) %>% filter(`Year-Month` == "2014-09-01") 
  
  SeptAQI = max(na.omit(county14$AQI))
  Sept_avgs[i] = SeptAQI
}
```

Avg AQI values for Sept 2014: 

```{r}
pollutants1_2014 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants1_2014_8.17.RData")
pollutants2_2014 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants2_2014_8.17.RData")

stationlats = c(unique(pollutants1_2014$latitude),unique(pollutants2_2014$latitude))
stationlongs = c(unique(pollutants1_2014$longitude),unique(pollutants2_2014$longitude))

station_points = data.frame(stationlats,stationlongs)

#Initializing map and station locations
ca_map <- map_data("county", region = "california")

#Match population dataset with ca_map
Sept_avgs = data.frame(Sept_avgs)
Sept_avgs = cbind(unique(ca_map$subregion),Sept_avgs)
colnames(Sept_avgs) = c("subregion","AQI")

merged_data <- merge(ca_map, Sept_avgs, by = "subregion", all.x = TRUE)

#Plot
gg_with_grouping <- ggplot() +
  geom_polygon(data = merged_data, aes(x = long, y = lat, group = group, fill = AQI), 
               color = "black") +
  coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
  theme_void() +
  labs(title = "") +
  scale_fill_gradient(low = "yellow", high = "red")

# Add points
gg_with_grouping <- gg_with_grouping +
  geom_point(data = station_points, aes(x = stationlongs, y = stationlats), 
             color = "blue", size = 1) + 
    theme(
    legend.text  = element_text(size = 14),  # legend labels
    legend.title = element_text(size = 16)   # legend title
  )

gg_with_grouping$labels$fill = "AQI Sept 2014"

print(gg_with_grouping)
```

```{r}
pollutants1_2014 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants1_2014_8.17.RData")
pollutants2_2014 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants2_2014_8.17.RData")

dates = c("2014-07-01","2014-08-01","2014-09-01","2014-10-01","2014-11-01","2014-12-01")

plot_list = list()

for(j in 1:6){
  Sept_avgs = c()

  for (i in 1:58){ 
    #Filter by county
    county14 = final_data14 %>% filter(stringr::str_starts(rownames(final_data14), counties[i])) %>% 
      filter(`Year-Month` == dates[j]) 
    
    SeptAQI = max(na.omit(county14$AQI))
    Sept_avgs[i] = SeptAQI
  }
  
  stationlats = c(unique(pollutants1_2014$latitude),unique(pollutants2_2014$latitude))
  stationlongs = c(unique(pollutants1_2014$longitude),unique(pollutants2_2014$longitude))
  
  station_points = data.frame(stationlats,stationlongs)
  
  #Initializing map and station locations
  ca_map <- map_data("county", region = "california")
  
  #Match population dataset with ca_map
  Sept_avgs = data.frame(Sept_avgs)
  Sept_avgs = cbind(unique(ca_map$subregion),Sept_avgs)
  colnames(Sept_avgs) = c("subregion","AQI")
  
  merged_data <- merge(ca_map, Sept_avgs, by = "subregion", all.x = TRUE)
  
  #Plot
  gg_with_grouping <- ggplot() +
    geom_polygon(data = merged_data, aes(x = long, y = lat, group = group, fill = AQI), 
                 color = "black") +
    coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
    theme_void() +
    labs(title = "") +
    scale_fill_gradient(low = "yellow", high = "red")
  
  # Add points
  gg_with_grouping <- gg_with_grouping +
    geom_point(data = station_points, aes(x = stationlongs, y = stationlats), 
               color = "blue", size = 1) + 
      theme(
      legend.text  = element_text(size = 14),  # legend labels
      legend.title = element_text(size = 16)   # legend title
    )
  
  gg_with_grouping$labels$fill = sprintf("AQI %s 2014",months[j])
  
  print(gg_with_grouping)  
  plot_list[[j]] = gg_with_grouping
}

combined = wrap_plots(plotlist = plot_list, ncol = 2)
combined

# Save one combined figure
ggsave(
  filename = paste0("aqi_combined_plot.png"),
  plot = combined,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
  width = 12,
  height = 15,
  dpi = 300
)
```



## HEATMAP OF POPULATION WITH STATION LOCATIONS MARKED (2015)

```{r}
pollutants1_2015 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants1_2015_8.17.RData")
pollutants2_2015 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants2_2015_8.17.RData")

stationlats = c(unique(pollutants1_2015$latitude),unique(pollutants2_2015$latitude))
stationlongs = c(unique(pollutants1_2015$longitude),unique(pollutants2_2015$longitude))

station_points = data.frame(stationlats,stationlongs)

#Initializing map and station locations
ca_map <- map_data("county", region = "california")

#Match population dataset with ca_map
#2010-2019 population data for CA 
USpops = read.csv("CA_census_pops1019.csv")
CApops = USpops %>% filter(STNAME == "California") %>% select(CTYNAME,POPESTIMATE2015)
CApops = CApops[-1,]

CApops$CTYNAME = unique(ca_map$subregion)
colnames(CApops) = c("subregion","pop")

merged_data <- merge(ca_map, CApops, by = "subregion", all.x = TRUE)

#Plot
gg_with_grouping <- ggplot() +
  geom_polygon(data = merged_data, aes(x = long, y = lat, group = group, fill = pop), 
               color = "black") +
  coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
  theme_void() +
  labs(title = "Heatmap of County Populations with 2015 Station Locations", fill = "Population") +
  scale_fill_gradient(low = "lightblue", high = "darkblue")

# Add points
gg_with_grouping <- gg_with_grouping +
  geom_point(data = station_points, aes(x = stationlongs, y = stationlats), 
             color = "red", size = 1.5)

print(gg_with_grouping)
```

## SKATER CLUSTERS PLOTTED WITH CUSTOM COLORS

```{r}
#Attach cluster labels to each county
clusterlabels = data.frame(CA_data_cluster$NAME,clus7_min$groups)
names(clusterlabels) = c("subregion","Cluster")

o = order(clusterlabels$subregion)
clusterlabels = clusterlabels[o,]
clusterlabels$subregion = tolower(clusterlabels$subregion)
clusterlabels$Cluster = factor(clusterlabels$Cluster)

merged_data <- merge(ca_map, clusterlabels, by = "subregion", all.x = TRUE)

# Define distinct colors for each category
#distinct_colors = qualitative_hcl(7,palette = "dynamic")
distinct_colors <- c("red", "blue", "green", "purple", "orange", "yellow", "brown")
distinct_colors <- c("red", "blue")

#Plot
gg_with_grouping <- ggplot() +
  geom_polygon(data = merged_data, aes(x = long, y = lat, group = group, fill = Cluster), 
               color = "black") +
  coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
  theme_void() +
  scale_fill_manual(values = distinct_colors) + 
  theme(
      title = element_text(size = 16),
      legend.text  = element_text(size = 20),  # legend labels
      legend.title = element_text(size = 20)   # legend title
    )

gg_with_grouping

ggsave(
  filename = paste0("skater7.2.png"),
  plot = gg_with_grouping,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
  width = 12,
  height = 12,
  dpi = 300
)
```

```{r}
library(magick)
save_path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs"

# read in both figures
map   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7.2.png")
heat  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/gfilter-7.2-heatmap.png")

# make sure they are the same height
# (this avoids stretching one)
common_height <- min(image_info(map)$height, image_info(heat)$height)
map_resized   <- image_resize(map,  paste0("x", common_height))
heat_resized  <- image_resize(heat, paste0("x", common_height))

# Combine columns side by side
combined <- image_append(c(map_resized,heat_resized), stack = FALSE)
combined_white <- image_background(combined, "white") %>%
                  image_flatten()

# save to file (same width+height as sum of both)
image_write(combined_white, path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/combined-spatial-dependence-7.2-white.png", format = "png")
```


## PLOT MAP OF CA WITH STATION LOCATIONS AND CLUSTERS

```{r}
#Initializing map and station locations
pollutants1_2019 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants1_2019_8.18.RData")
pollutants2_2019 = readRDS("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/EPA data/Raw/pollutants2_2019_8.18.RData")

stationlats = c(unique(pollutants1_2019$latitude),unique(pollutants2_2019$latitude))
stationlongs = c(unique(pollutants1_2019$longitude),unique(pollutants2_2019$longitude))

station_points = data.frame(stationlats,stationlongs)

#Initializing map and station locations
ca_map <- map_data("county", region = "california")

# #Stations measuring SO2 for 2014
# station_points = data.frame(
#   longitude = all_pollutants_station_2014data[[3]]$longitude,
#   latitude = all_pollutants_station_2014data[[3]]$latitude
# )

#Attach cluster labels to each county
clusterlabels = data.frame(CA_data_cluster$NAME,clus7_min$groups)
names(clusterlabels) = c("subregion","Cluster")

o = order(clusterlabels$subregion)
clusterlabels = clusterlabels[o,]
clusterlabels$subregion = tolower(clusterlabels$subregion)
clusterlabels$Cluster = factor(clusterlabels$Cluster)

merged_data <- merge(ca_map, clusterlabels, by = "subregion", all.x = TRUE)

# Define distinct colors for each category
distinct_colors <- c("red", "blue", "green", "purple", "orange", "yellow", "brown")

#Plot
gg_with_grouping <- ggplot() +
  geom_polygon(data = merged_data, aes(x = long, y = lat, group = group, fill = Cluster), 
               color = "black") +
  coord_fixed(ratio = 1.3, xlim = c(-125, -112), ylim = c(30, 42)) +
  theme_void() +
  labs(title = "2019") +
  scale_fill_manual(values = distinct_colors)

# Add points
gg_with_grouping <- gg_with_grouping +
  geom_point(data = station_points, aes(x = stationlongs, y = stationlats), 
             color = "black", size = 1.5) + 
  theme(
      title = element_text(size = 14),
      legend.text  = element_text(size = 14),  # legend labels
      legend.title = element_text(size = 16)   # legend title
    )

print(gg_with_grouping)



plot6 = gg_with_grouping
```

```{r}
# read in both figures
plot_list = list(plot1,plot2,plot3,plot4,plot5,plot6)

combined = wrap_plots(plotlist = plot_list, ncol = 2)
combined

# Save one combined figure
ggsave(
  filename = paste0("aqi_stations_combined_plot.png"),
  plot = combined,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
  width = 12,
  height = 15,
  dpi = 300
)
```


## ADJACENCY GRAPH OF CA WITH NODES PLOTTED AT POP-WEIGHTED CENTROID OF EACH CLUSTER 

Identify pop weighted centroids for each cluster 

```{r}
#2010-2019 population data for CA 
USpops = read.csv("CA_census_pops1019.csv")
CApops = USpops %>% filter(STNAME == "California") %>% select(CTYNAME,POPESTIMATE2015)
CApops = CApops[-1,]


#Attach cluster labels to each county
clusterlabels = data.frame(CA_data_cluster$NAMELSAD,CA_data_cluster$INTPTLAT,CA_data_cluster$INTPTLON,clus7_min$groups)
names(clusterlabels) = c("CTYNAME","Lat","Long","Cluster")

o = order(clusterlabels$CTYNAME)
clusterlabels = clusterlabels[o,]
clusterlabels$Cluster = factor(clusterlabels$Cluster)

merged_data <- merge(CApops, clusterlabels, by = "CTYNAME", all.x = TRUE)
merged_data$Lat = as.numeric(merged_data$Lat)
merged_data$Long = as.numeric(merged_data$Long)


# Calculate Population-Weighted Centroids
centroid_data <- merged_data %>%
  group_by(Cluster) %>%
  summarize(
    WeightedLat = weighted.mean(Lat, POPESTIMATE2015),
    WeightedLong = weighted.mean(Long, POPESTIMATE2015)
  )
```

Make the plot: 

```{r}
library(leaflet)

adj_matrix <- matrix(c(
    0, 0, 1, 1, 1,
    0, 0, 1, 1, 1,
    1, 1, 0, 1, 1,
    1, 1, 1, 0, 1,
    1, 1, 1, 1, 0
), nrow = 5, byrow = TRUE)

#Nodes are specific cities 

# node_coords <- matrix(c(
#     34.0522, -118.2437,   # Los Angeles
#     37.7749, -122.4194,   # San Francisco
#     32.7157, -117.1611,   # San Diego
#     38.5816, -121.4944,   # Sacramento
#     36.7783, -119.4179    # Fresno
# ), nrow = 5, byrow = TRUE)

#Nodes are population weighted centroids of each cluster 

node_coords <- matrix(c(
    37.27924, -121.5303,   # Cluster 1
    38.97130, -121.2390,   # Cluster 2
    38.86888, -122.9104,   # Cluster 3
    34.24761, -117.8457,   # Cluster 4
    38.11163, -121.8772    # Cluster 5
), nrow = 5, byrow = TRUE)


california_map <- leaflet() %>% addTiles() %>%
  setView(lng = -119.4179, lat = 36.7783, zoom = 6)


for (i in 1:5) {
    california_map <- addMarkers(
        california_map,
        lng = node_coords[i, 2],
        lat = node_coords[i, 1],
        popup = paste("Node", i)
    )
}

for (i in 1:4) {
    for (j in (i + 1):5) {
        if (adj_matrix[i, j] == 1) {
            california_map <- addPolylines(
                california_map,
                lng = c(node_coords[i, 2], node_coords[j, 2]),
                lat = c(node_coords[i, 1], node_coords[j, 1]),
                color = "blue"
            )
        }
    }
}

california_map
```


# Plotting successive estimated graphs from HUGE (color coded)

SKATER CLUSTERING: 

```{r}
#Identify neighborhood list for counties 
CA_nb = poly2nb(CA_spdf)

#Calculate edge costs (dissimilarity matrix) based on Euclidean distance 
costs <- nbcosts(CA_nb, data = covariates_scale)

###Get adjacency matrix using nb2mat() (SEPARATE STEP FOR INLA)
adj = nb2mat(CA_nb,style = "B")

#Style means the coding scheme style used to create the weighting matrix 
# B: basic binary coding scheme
# W: row standardized coding scheme 
# C: globally standardized coding scheme  
# U: values of C / number of neighbors 
# S: variance stabilizing coding scheme 

#Transform edge costs to spatial weights 
ct_w <- nb2listw(CA_nb,costs,style="B")

#Create minimum spanning tree 
ct_mst <- mstree(ct_w)

#Run SKATER algorithm to get 5-10 contiguous clusters (cluster idx is in order of CA_sf)
clusterlabels = list()

for (i in 4:9){
  skater_clusters <- skater(edges = ct_mst[,1:2], data = covariates_scale, ncuts = i)
  
  #Determine an appropriate minimum population threshold based on???
  # pops_summary = summary(unique(CA_data$Total_Pop))
  # pops_summary
  # 
  # #Idea 1: Use median * (how many counties should be in a cluster at minimum)
  # min_pop = as.numeric(pops_summary[3] * 4)
  # 
  # #Idea 2: If we assume CA population is 39M, divide total pop by # clusters
  # min_pop2 = 39000000 / 5
  # 
  # #Add a min population constraint
  # skater_clusters <- skater(edges = ct_mst[,1:2], 
  #                      data = covariates_scale, 
  #                      crit = min_pop2, 
  #                      vec.crit = CA_data$Total_Pop,
  #                      ncuts = i)
  # 
  # #Add a minimum number of areas in each cluster constraint 
  # skater_clusters = skater(edges = ct_mst[,1:2], data = covariates_scale, ncuts = i, 4)
  
  
  clusterlabels[[i]] = data.frame(CA_data_cluster$NAME,skater_clusters$groups)
  names(clusterlabels[[i]]) = c("counties","Cluster")
}

clusterlabels = clusterlabels[-c(1:3)]
```

HUGE ESTIMATION:

```{r,cache = FALSE}
est_graphs = list()

for (k in 5:10){
 #Aggregate feature vectors into one vector for each SKATER cluster
  CA_cluster = data.frame(CA_sf$NAMELSAD,clusterlabels[[k-4]]$Cluster)
  names(CA_cluster) = c("County","Cluster")
  year = 2010:2019
  
  CA_cluster = left_join(CA_cluster,CA_data,by = "County")
  
  #Get weighted avg value for Score for each cluster for each year 
  #Create new data matrix of aggregated feature vectors 
  cluster_features = matrix(NA,nrow = 10,ncol = k)
  
  for (i in 1:k){
    cluster = CA_cluster %>% filter(Cluster == i)
  
    for(j in 1:10){
      #Obtain a weighted mean based on population
      vec = cluster %>% filter(Year == year[j]) %>% select(Score,Total_Pop) %>% unique()
      cluster.pop = sum(vec$Total_Pop)
      cluster.popweights = vec$Total_Pop/cluster.pop
      cluster_features[j,i] = weighted.mean(vec$Score,cluster.popweights)
    }
  }
  
  #Graph learning w HUGE
  out.glasso = huge(cluster_features,lambda = seq(0.95,0.05,by=-0.05),method="glasso")
  
  glasso.ebic = huge.select(out.glasso,criterion = "ebic")
  
  est_graphs[[k-4]] = glasso.ebic$refit
}
```

VISUALIZING ESTIMATED GRAPH:

```{r}
# Install and load the necessary packages
if (!requireNamespace("igraph", quietly = TRUE)) {
  install.packages("igraph")
}
library(igraph)

# Function to visualize an adjacency matrix as a graph with consistent node coloring
visualizeGraph <- function(adjacency_matrix, cluster_labels, main_title) {
  graph <- graph_from_adjacency_matrix(adjacency_matrix, mode = "undirected")

  # Define a set of distinct colors for cluster labels 1 to 10
  distinct_colors <- c("red", "royalblue", "olivedrab", "purple3", "orange", "lawngreen", "magenta1", "plum2", "turquoise1", "yellow")

  # Assign colors to nodes based on cluster labels
  node_colors <- distinct_colors[1:max(cluster_labels)]

  # Plot the graph with consistent node colors
  plot(graph, main = main_title, vertex.color = node_colors)
}
```



```{r}
original_clusters_list = list()

for (a in 1:6){
  skater_clusters <- clusterlabels[[a]]$Cluster
  original_clusters_list[[a]] <- skater_clusters
  
  huge_adjacency_matrix <- est_graphs[[a]]
  
  # Visualize the clustering result with the adjacency matrix for k = 5
  main_title <- "SKATER Clustering Result with HUGE Graph Estimation"
  visualizeGraph(huge_adjacency_matrix,skater_clusters, main_title)
}
```


```{r}
library(magick)
save_path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs"

# read in both figures
plot1   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/ref3-prec-7.2-heatmap.png")
plot2  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr1-prec-7.2-heatmap.png")
plot3   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr2-prec-7.2-heatmap.png")
plot4  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr3-prec-7.2-heatmap.png")
plot5   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr4-prec-7.2-heatmap.png")
plot6  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr5-prec-7.2-heatmap.png")


# # make sure they are the same height
# # (this avoids stretching one)
# common_height <- min(image_info(map)$height, image_info(heat)$height)
# map_resized   <- image_resize(map,  paste0("x", common_height))
# heat_resized  <- image_resize(heat, paste0("x", common_height))

# Make first column (stacked vertically)
col1 <- image_append(c(plot1, plot3, plot5), stack = TRUE)

# Make second column
col2 <- image_append(c(plot2, plot4, plot6), stack = TRUE)

# Combine columns side by side
combined <- image_append(c(col1, col2), stack = FALSE)

# save to file (same width+height as sum of both)
image_write(combined, path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/prec-7.2-heatmaps-combined.png", format = "png")
```


```{r}
plot1   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/ref1-outsample-combined.png")
plot2  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/ref3-outsample-combined.png")
plot3   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr1-outsample-combined.png")
plot4  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr2-outsample-combined.png")
plot5   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr3-outsample-combined.png")
plot6  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr5-outsample-combined.png")


# # make sure they are the same height
# # (this avoids stretching one)
# common_height <- min(image_info(map)$height, image_info(heat)$height)
# map_resized   <- image_resize(map,  paste0("x", common_height))
# heat_resized  <- image_resize(heat, paste0("x", common_height))

# First stacked image with plots 1–3
stack1 <- image_append(c(plot1, plot2, plot3), stack = TRUE)

# Second stacked image with plots 4–6
stack2 <- image_append(c(plot4, plot5, plot6), stack = TRUE)

# Save them
image_write(stack1, "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/outsample-fits-combined1.png")
image_write(stack2, "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/outsample-fits-combined2.png")
```


SKATER experiment combined plots: 

```{r}
library(magick)
save_path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs"

# read in both figures
plot1   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-adjHHincome.png")
plot2  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-belowpoverty.png")
plot3   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-whitecollar.png")
plot4  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-allsubindices.png")
plot5   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-educ2.png")
plot6  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-income-indices.png")


# # make sure they are the same height
# # (this avoids stretching one)
# common_height <- min(image_info(map)$height, image_info(heat)$height)
# map_resized   <- image_resize(map,  paste0("x", common_height))
# heat_resized  <- image_resize(heat, paste0("x", common_height))

# Make first column (stacked vertically)
row1 <- image_append(c(plot1, plot2, plot3), stack = FALSE)

# Make second column
row2 <- image_append(c(plot4, plot5, plot6), stack = FALSE)

# Combine columns side by side
combined <- image_append(c(row1,row2), stack = TRUE)

# save to file (same width+height as sum of both)
image_write(combined, path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-experiment1.png", format = "png")
```

```{r}
library(magick)
save_path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs"

# read in both figures
plot1   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-adjHHincome.png")
plot2  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-belowpoverty.png")
plot3   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-whitecollar.png")
plot4  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-allsubindices.png")
plot5   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-educ2.png")
plot6  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-income-indices.png")


# # make sure they are the same height
# # (this avoids stretching one)
# common_height <- min(image_info(map)$height, image_info(heat)$height)
# map_resized   <- image_resize(map,  paste0("x", common_height))
# heat_resized  <- image_resize(heat, paste0("x", common_height))

# Make first column (stacked vertically)
row1 <- image_append(c(plot1, plot2, plot3), stack = FALSE)

# Make second column
row2 <- image_append(c(plot4, plot5, plot6), stack = FALSE)

# Combine columns side by side
combined <- image_append(c(row1,row2), stack = TRUE)

# save to file (same width+height as sum of both)
image_write(combined, path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-experiment1.png", format = "png")


#####################################################################################


plot1   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-1013.png")
plot2  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-1316.png")
plot3   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-1619.png")
# plot4  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr2-outsample-combined.png")
# plot5   <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr3-outsample-combined.png")
# plot6  <- image_read("C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/kgr5-outsample-combined.png")


# # make sure they are the same height
# # (this avoids stretching one)
# common_height <- min(image_info(map)$height, image_info(heat)$height)
# map_resized   <- image_resize(map,  paste0("x", common_height))
# heat_resized  <- image_resize(heat, paste0("x", common_height))

# First stacked image with plots 1–3
row <- image_append(c(plot1, plot2, plot3), stack = FALSE)

# # Second stacked image with plots 4–6
# stack2 <- image_append(c(plot4, plot5, plot6), stack = TRUE)

# Save them
image_write(row, "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/skater7-experiment2.png")
# image_write(stack2, "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/outsample-fits-combined2.png")
```

