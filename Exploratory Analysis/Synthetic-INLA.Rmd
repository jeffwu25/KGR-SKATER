---
title: "Synthetic data fitting"
author: "Jeffrey Wu"
date: "2023-10-30"
output: html_document
---

# In sample fit experiment

## Poisson data with fixed intensity and seasonal pattern 

```{r}
library(astsa)
library(INLA)
library(brinla)
library(dplyr)
library(ggplot2)

set.seed(10)

# Set the fixed intensity
lambda <- 5
time_intervals <- 1:72

# Define a monthly sine wave pattern for seasonality
seasonal_pattern <- exp(sin(2 * pi * time_intervals / 12) + lambda)

# Simulate Poisson data with seasonality
simulated_data <- rpois(72,seasonal_pattern)

# Print the simulated data
tsplot(simulated_data)
```





INLA model 1: Poisson GLMM

```{r}
months = rep(1:12,6)
id = rep(1,72)

simulated_data = data.frame(months,id,simulated_data)
simulated_data$months = factor(simulated_data$months)
colnames(simulated_data)[3] = "response"

formula1 = response ~ months + f(id,model = "iid")
model1 = inla(formula1,family = "poisson",data = simulated_data)

#Get model summaries
model1$summary.fixed
bri.hyperpar.summary(model1)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(model1$summary.fixed$mean)
names(multeff) <- model1$names.fixed
multeff

preds_model1 = model1$summary.fitted.values
tsplot(round(preds_model1$mean))
```

## Poisson data with deterministic intensity (sinusoidal) and seasonal pattern 

```{r}
# Define a time-dependent intensity function (e.g., a linear increase)
lambda0 <- 5
slope = 2.5
time_intervals <- 1:72
time_trend = (time_intervals/72)*slope + lambda0

# Define a monthly sine wave pattern for seasonality
seasonal_pattern <- sin(2 * pi * time_intervals / 12)

# Simulate Poisson data with seasonality
simulated_data1 <- rpois(72, time_trend + seasonal_pattern)

# Print the simulated data
tsplot(simulated_data1)
```

INLA model 1: Poisson GLMM

```{r}
simulated_data1 = data.frame(months,id,simulated_data1)
simulated_data1$months = factor(simulated_data1$months)
colnames(simulated_data1)[3] = "response"

formula1 = response ~ months + f(id,model = "iid")
model1 = inla(formula1,family = "poisson",data = simulated_data1)

#Get model summaries
model1$summary.fixed
bri.hyperpar.summary(model1)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(model1$summary.fixed$mean)
names(multeff) <- model1$names.fixed
multeff

preds_model1 = model1$summary.fitted.values
tsplot(round(preds_model1$mean))
```

## LGCP data 

```{r}
library(MASS)
library(mvtnorm)
library(huge)

# set.seed(123)
num_clus = 50

#Simulate data with some sparsity structure
data = huge.generator(n=72,d=num_clus,graph="cluster")
plot(data)

#Grab sample covariance matrix and generate MVN data with it 
scov = data$sigmahat
adj = data$theta
adj = as.matrix(adj)

#Set avg intensity to 5 (w seasonal pattern)
lambda = 5
simulated_data4 = mvrnorm(n=72,rep(lambda,num_clus),scov) 

#Define a monthly sine wave pattern for seasonality
pois_rates = exp(sin(2 * pi * time_intervals / 12) + simulated_data4)

simulated_data4 = apply(pois_rates,2,rpois,n=72)

detach("package:MASS", unload = TRUE)
detach("package:huge", unload = TRUE)
library(dplyr)
library(ggplot2)

tsplot(simulated_data4[,1])

cox_data = simulated_data4[,1]
for (i in 2:num_clus){
  cox_data = c(cox_data,simulated_data4[,i])
}

id = rep(1:num_clus,each = 72)
id2 = 1:(num_clus*72)
months = rep(1:12,(6*num_clus))
time = rep(1:72,num_clus)

synthetic_lgcp_data = data.frame(time,months,id,id2,cox_data)
synthetic_lgcp_data$months = factor(synthetic_lgcp_data$months)
colnames(synthetic_lgcp_data)[5] = "response"
```

INLA model 1: Poisson GLMM

```{r}
formula1 = response ~ months + f(id,model = "iid")
model1 = inla(formula1,family = "poisson",data = synthetic_lgcp_data)

#Get model summaries
model1$summary.fixed
bri.hyperpar.summary(model1)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(model1$summary.fixed$mean)
names(multeff) <- model1$names.fixed
multeff

preds_model1 = model1$summary.fitted.values
# preds_model1$mean = round(preds_model1$mean)
preds_model1 = cbind(synthetic_lgcp_data$id,preds_model1)
colnames(preds_model1) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")


for (i in 1:10){
df = synthetic_lgcp_data %>% filter(id == i) %>% select(time,response)
preds = preds_model1 %>% filter(id == i) 
df = cbind(df,preds)

title = sprintf("Posterior Predictive Fits for Cluster %s",i)

post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + 
  geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = `0.025quant`,ymax = `0.975quant`),alpha = 0.3) + ggtitle(title)
print(post_pred_plot)
}
```

INLA model 2: BYM model

```{r}
formula2 = response ~ months + f(id, model = "bym", graph = adj) 
model2 = inla(formula2,family = "poisson",data = synthetic_lgcp_data)

#Get model summaries
model2$summary.fixed
bri.hyperpar.summary(model2)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(model2$summary.fixed$mean)
names(multeff) <- model2$names.fixed
multeff

preds_model2 = model2$summary.fitted.values
# preds_model2$mean = round(preds_model2$mean)
preds_model2 = cbind(synthetic_lgcp_data$id,preds_model2)
colnames(preds_model2) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")


for (i in 1:10){
df = synthetic_lgcp_data %>% filter(id == i) %>% select(time,response)
preds = preds_model2 %>% filter(id == i) 
df = cbind(df,preds)

title = sprintf("Posterior Predictive Fits for Cluster %s",i)

post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + 
  geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = `0.025quant`,ymax = `0.975quant`),alpha = 0.3) + ggtitle(title)
print(post_pred_plot)
}
```

INLA model 3: generic0 setting: 

```{r}
prec = solve(scov)
kgr_formula2 = response ~ months + f(id,model = "generic0",Cmatrix = prec)

#Formula 2
kgr_model = inla(kgr_formula2, data = synthetic_lgcp_data, family = "poisson")

kgr_model$summary.fixed
bri.hyperpar.summary(kgr_model)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(kgr_model$summary.fixed$mean)
names(multeff) <- kgr_model$names.fixed
multeff

preds_kgr = kgr_model$summary.fitted.values
# preds_kgr$mean = round(preds_kgr$mean)
preds_kgr = cbind(synthetic_lgcp_data$id,preds_kgr)
colnames(preds_kgr) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")

for (i in 1:10){
df = synthetic_lgcp_data %>% filter(id == i) %>% select(time,response)
preds = preds_kgr %>% filter(id == i) 
df = cbind(df,preds)

title = sprintf("Posterior Predictive Fits for Cluster %s",i)

post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + 
  geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = `0.025quant`,ymax = `0.975quant`),alpha = 0.3) + ggtitle(title)
print(post_pred_plot)
}
```

# Proper simulation study (100 iterations of model fitting)

```{r,warning=FALSE,echo=FALSE}
library(dplyr)
library(ggplot2)

synth_data_list = list()
fvs_model1_list = list()
fvs_model2_list = list()
fvs_model3_list = list()

model1_int = c()
model2_int = c()
model3_int = c()

for (k in 1:1000){
  library(MASS)
  library(mvtnorm)
  library(huge)
  
  num_clus = 50

  #Simulate data with some sparsity structure
  data = huge.generator(n=72,d=num_clus,graph="cluster")
  
  #Grab sample covariance matrix and generate MVN data with it 
  scov = data$sigmahat
  adj = data$theta
  adj = as.matrix(adj)
  
  #Set avg intensity to 5 (w seasonal pattern)
  lambda = 5
  simulated_data4 = mvrnorm(n=72,rep(lambda,num_clus),scov) 
  
  #Define a monthly sine wave pattern for seasonality
  pois_rates = exp(sin(2 * pi * time_intervals / 12) + simulated_data4)
  
  simulated_data4 = apply(pois_rates,2,rpois,n=72)
  
  detach("package:MASS", unload = TRUE)
  detach("package:huge", unload = TRUE)
  
  cox_data = simulated_data4[,1]
  for (i in 2:num_clus){
    cox_data = c(cox_data,simulated_data4[,i])
  }
  
  id = rep(1:num_clus,each = 72)
  id2 = 1:(num_clus*72)
  months = rep(1:12,(6*num_clus))
  time = rep(1:72,num_clus)
  
  synthetic_lgcp_data = data.frame(time,months,id,id2,cox_data)
  synthetic_lgcp_data$months = factor(synthetic_lgcp_data$months)
  colnames(synthetic_lgcp_data)[5] = "response"
  
  synth_data_list[[k]] = synthetic_lgcp_data
  
  ###Model 1
  
  formula1 = response ~ months + f(id,model = "iid")
  model1 = inla(formula1,family = "poisson",data = synth_data_list[[k]])
  
  preds_model1 = model1$summary.fitted.values
  # preds_model1$mean = round(preds_model1$mean)
  preds_model1 = cbind(synth_data_list[[k]]$id,preds_model1)
  colnames(preds_model1) = c("id","mean","sd","0.025quant",
                                 "0.5quant","0.975quant","mode")
  
  fvs_model1_list[[k]] = preds_model1
  model1_int[k] = model1$summary.fixed[[1]][1]
  
  
  ###Model 2
  
  formula2 = response ~ months + f(id, model = "bym", graph = adj) 
  model2 = inla(formula2,family = "poisson",data = synth_data_list[[k]])
  
  preds_model2 = model2$summary.fitted.values
  # preds_model2$mean = round(preds_model2$mean)
  preds_model2 = cbind(synth_data_list[[k]]$id,preds_model2)
  colnames(preds_model2) = c("id","mean","sd","0.025quant",
                                 "0.5quant","0.975quant","mode")
  
  fvs_model2_list[[k]] = preds_model2
  model2_int[k] = model2$summary.fixed[[1]][1]
  
  
  ###Model 3
  prec = solve(scov)
  kgr_formula2 = response ~ months + f(id,model = "generic0",Cmatrix = prec)
  kgr_model = inla(kgr_formula2, data = synth_data_list[[k]], family = "poisson")
  
  preds_kgr = kgr_model$summary.fitted.values
  # preds_kgr$mean = round(preds_kgr$mean)
  preds_kgr = cbind(synth_data_list[[k]]$id,preds_kgr)
  colnames(preds_kgr) = c("id","mean","sd","0.025quant",
                                 "0.5quant","0.975quant","mode")
  
  fvs_model3_list[[k]] = preds_kgr
  model3_int[k] = kgr_model$summary.fixed[[1]][1]
}
```

Making a plot of MSE (at each location) over time

```{r}
mse_df = data.frame(1,2,3)
colnames(mse_df) = c("Time","MSE","Model")

for (j in 1:72){
  for (i in 1:length(synth_data_list)){
  true_data = synth_data_list[[i]] %>% filter(time == j)
  fvs1 = fvs_model1_list[[i]] %>% filter(time == j)
  fvs2 = fvs_model2_list[[i]] %>% filter(time == j)
  fvs3 = fvs_model3_list[[i]] %>% filter(time == j)
  
  mse_model1 = sqrt(mean((true_data$response - fvs1$mean)^2))
  mse_model2 = sqrt(mean((true_data$response - fvs2$mean)^2))
  mse_model3 = sqrt(mean((true_data$response - fvs3$mean)^2))
  
  mse_model1 = cbind(j,mse_model1,"Model 1")
  mse_model2 = cbind(j,mse_model2,"Model 2")
  mse_model3 = cbind(j,mse_model3,"Model 3")
  df_new = data.frame(rbind(mse_model1,mse_model2,mse_model3))
  colnames(df_new) = c("Time","MSE","Model")
  
  mse_df = rbind(mse_df,df_new)
  }
}

mse_df = mse_df[-1,]
mse_df$Time = as.numeric(mse_df$Time)
mse_df$MSE = as.numeric(mse_df$MSE)
```


USE THIS PLOT: 

```{r}
# Create a boxplot using ggplot2 with facets and adjusted height
library(ggplot2)
library(ggthemes)

ggplot(mse_df, aes(x = as.factor(Time), y = MSE, fill = Model)) +
  geom_boxplot(width = 0.7) +  # Adjust width as needed
  facet_wrap(~ Model, scales = "free_y", nrow = 3, strip.position = "bottom") +
  labs(
    title = "",
    x = "Time Points",
    y = "RMSE"
  ) +
  theme_gray() + 
  scale_x_discrete(breaks = seq(0,72,by=12))
```



```{r}
# Create individual plots for each model
plot_model1 <- ggplot(mse_df[mse_df$Model == "Model 1", ], aes(x = as.factor(Time), y = MSE, fill = Model)) +
  geom_boxplot(width = 0.7, fill = "red") +
  labs(
    title = "Model 1 - Mean Squared Errors Over Time",
    x = NULL,  # No x-axis label
    y = NULL
  ) +
  theme_gray()

plot_model2 <- ggplot(mse_df[mse_df$Model == "Model 2", ], aes(x = as.factor(Time), y = MSE, fill = Model)) +
  geom_boxplot(width = 0.7, fill = "green") +
  labs(
    title = "Model 2 - Mean Squared Errors Over Time",
    x = NULL,  # No x-axis label
    y = "Mean Squared Error"
  ) +
  theme_gray()

plot_model3 <- ggplot(mse_df[mse_df$Model == "Model 3", ], aes(x = as.factor(Time), y = MSE, fill = Model)) +
  geom_boxplot(width = 0.7, fill = "blue") +
  labs(
    title = "Model 3 - Mean Squared Errors Over Time",
    x = "Time Points",
    y = NULL
  ) +
  theme_gray()

# Combine the plots vertically using grid.arrange
library(gridExtra)
grid.arrange(plot_model1, plot_model2, plot_model3, ncol = 1)
```

```{r}
density_data <- data.frame(
  Value = c(model1_int, model2_int, model3_int),
  Model = rep(c("Model 1", "Model 2", "Model 3"), each = 602)
)

ggplot(density_data, aes(x = Value, color = Model)) +
  geom_density(size = 1) +  # Only density lines without shading
  geom_vline(xintercept = 5, linetype = "dashed", color = "black", size = 1) +  # Vertical line at x = 5
  labs(
    title = "",
    x = "Values",
    y = "Density"
  ) +
  scale_color_manual(values = c("Model 1" = "red", "Model 2" = "green", "Model 3" = "blue")) +
  theme_gray() + 
  coord_cartesian(xlim = c(3,7)) + 
  facet_grid(Model ~ ., scales = "free_y")

###Densities plotted on top of each other 
# ggplot(density_data, aes(x = Value, color = Model)) +
#   geom_density(size = 1) +  # Only density lines without shading
#   geom_vline(xintercept = 5, linetype = "dashed", color = "black", size = 1) +  # Vertical line at x = 5
#   labs(
#     title = "Density Curves for Three Models",
#     x = "Values",
#     y = "Density"
#   ) +
#   scale_color_manual(values = c("Model 1" = "blue", "Model 2" = "green", "Model 3" = "red")) +
#   theme_minimal() +
#   coord_cartesian(xlim = c(3,7))  # Set x-axis range

# hist(model1_int)
# hist(model2_int)
# hist(model3_int)

mean(model1_int)
mean(model2_int)
mean(model3_int)
```



# Out of sample fit experiment 

## LGCP data 

```{r}
library(MASS)
library(mvtnorm)
library(huge)
library(dplyr)
library(ggplot2)

#Simulate data with some sparsity structure
data = huge.generator(n=1020,d=8,graph="cluster")
plot(data)

#Grab sample covariance matrix and generate MVN data with it 
scov = data$sigmahat
adj = data$theta
adj = as.matrix(adj)
simulated_data4 = mvrnorm(n=1020,rep(5,8),scov) #set avg intensity to 0, then 1, 2...

pois_rates = exp(simulated_data4)

simulated_data4 = apply(pois_rates,2,rpois,n=1020)

tsplot(simulated_data4[,4])

#Set up dataset
cox_data = simulated_data4[,1]
for (i in 2:8){
  cox_data = c(cox_data,simulated_data4[,i])
}

id = rep(1:8,each = 1020)
time = rep(1:1020,8)
months = rep(1:12,85)

simulated_data4 = data.frame(months,id,time,cox_data)
simulated_data4$months = factor(simulated_data4$months)
colnames(simulated_data4)[4] = "response"
```

```{r}
#Split dataset into training and test 
out_sample = which(simulated_data4$time > 960)
simulated_test_data = simulated_data4
simulated_test_data$response[out_sample] = NA
```


INLA model 1: Poisson GLMM

```{r}
formula1 = response ~ f(id,model = "iid")
model1 = inla(formula1,family = "poisson",data = simulated_test_data,
              control.predictor = list(compute = TRUE, link = 1))

#Get model summaries
model1$summary.fixed
bri.hyperpar.summary(model1)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(model1$summary.fixed$mean)
names(multeff) <- model1$names.fixed
multeff

preds_model1 = model1$summary.fitted.values
# preds_model1$mean = round(preds_model1$mean)
preds_model1 = cbind(simulated_data4$id,preds_model1)
colnames(preds_model1) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")

for (i in 1:8){
  df = preds_model1 %>% filter(id == i)
  tsplot(df$mean)
}
```

INLA model 2: BYM model

```{r}
formula2 = response ~ months + f(id, model = "bym", graph = adj) 
model2 = inla(formula2,family = "poisson",data = simulated_test_data,
              control.predictor = list(compute = TRUE, link = 1))

#Get model summaries
model2$summary.fixed
bri.hyperpar.summary(model2)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(model2$summary.fixed$mean)
names(multeff) <- model2$names.fixed
multeff

preds_model2 = model2$summary.fitted.values
# preds_model2$mean = round(preds_model2$mean)
preds_model2 = cbind(simulated_data4$id,preds_model2)
colnames(preds_model2) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")

for (i in 1:8){
  df = preds_model2 %>% filter(id == i)
  tsplot(df$mean)
}
```

INLA model w generic0 setting: 

```{r}
sprec = solve(scov)
sprec = apply(sprec,2,jitter)

kgr_formula1 = response ~ f(id,model = "generic0",Cmatrix = sprec)

#Formula 1
kgr_model = inla(kgr_formula1, data = simulated_test_data, family = "poisson",
                 control.predictor = list(compute = TRUE, link = 1))

kgr_model$summary.fixed
bri.hyperpar.summary(kgr_model)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(kgr_model$summary.fixed$mean)
names(multeff) <- kgr_model$names.fixed
multeff

preds_kgr = kgr_model$summary.fitted.values
# preds_kgr$mean = round(preds_kgr$mean)
preds_kgr = cbind(simulated_data4$id,preds_kgr)
colnames(preds_kgr) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")

for (i in 1:8){
  df = preds_kgr %>% filter(id == i)
  tsplot(df$mean)
}
```


# Fitting INLA models to clusters of very different scales 

```{r}
library(MASS)
library(mvtnorm)
library(huge)
library(dplyr)
library(ggplot2)

#Simulate data with some sparsity structure
data = huge.generator(n=60,d=2,graph="cluster")
plot(data)

#Grab sample covariance matrix and generate MVN data with it 
scov = data$sigmahat
adj = data$theta
adj = as.matrix(adj)
simulated_data5 = mvrnorm(n=60,c(2,10),scov) #set avg intensity to 0, then 1, 2...

pois_rates = exp(simulated_data5)

simulated_data5 = apply(pois_rates,2,rpois,n=60)

#Set up dataset
cox_data = c(simulated_data5[,1],simulated_data5[,2])

id = rep(1:2,each = 60)
time = rep(1:60,2)
months = rep(1:12,5)

simulated_data5 = data.frame(months,id,time,cox_data)
simulated_data5$months = factor(simulated_data5$months)
colnames(simulated_data5)[4] = "response"

#Split dataset into training and test 
out_sample = which(simulated_data5$time > 54)
simulated_test_data2 = simulated_data5
simulated_test_data2$response[out_sample] = NA
```


INLA model w generic0 setting: 

```{r}
sprec = solve(scov)
sprec = apply(sprec,2,jitter)

kgr_formula = response ~ f(id,model = "generic0",Cmatrix = sprec)

#Formula 1
kgr_model = inla(kgr_formula, data = simulated_test_data2, family = "poisson",
                 control.predictor = list(compute = TRUE, link = 1))

kgr_model$summary.fixed
bri.hyperpar.summary(kgr_model)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(kgr_model$summary.fixed$mean)
names(multeff) <- kgr_model$names.fixed
multeff

preds_kgr = kgr_model$summary.fitted.values
# preds_kgr$mean = round(preds_kgr$mean)
preds_kgr = cbind(simulated_data5$id,preds_kgr)
colnames(preds_kgr) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")

for (i in 1:2){
  df = simulated_data5 %>% filter(id == i) %>% select(response,time)
  preds = preds_kgr %>% filter(id == i) 
  df = cbind(df,preds)
  
  title = sprintf("Posterior Predictive Fits for Cluster %s",i)
  
  post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + 
    geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = `0.025quant`,ymax = `0.975quant`),alpha = 0.3) + geom_vline(xintercept = 54,linetype = "dashed",color = "blue",linewidth = 1.5) + ggtitle(title)
  print(post_pred_plot)
}
```

```{r,warning=FALSE}
quantized_data = simulated_data5 
clus1_data = quantized_data %>% filter(id == 1)
clus2_data = quantized_data %>% filter(id == 2)

clus1_data$response = clus1_data$response+2
clus2_data$response = floor(clus2_data$response/1000)

quantized_data$response[which(quantized_data$id == 1)] = clus1_data$response
quantized_data$response[which(quantized_data$id == 2)] = clus2_data$response

omit_idx = which(quantized_data$time > 54)
quantized_out_data = quantized_data
quantized_out_data$response[omit_idx] = NA

new_fit = inla(kgr_formula, data = quantized_out_data, family = "poisson",
                 control.predictor = list(compute = TRUE, link = 1))

new_fit$summary.fixed
bri.hyperpar.summary(new_fit)

#Exponentiating parameter to get better interpretation of estimates 
multeff <- exp(new_fit$summary.fixed$mean)
names(multeff) <- new_fit$names.fixed
multeff

preds_kgr2 = new_fit$summary.fitted.values
# preds_kgr$mean = round(preds_kgr$mean)
preds_kgr2 = cbind(simulated_data5$id,preds_kgr2)
colnames(preds_kgr2) = c("id","mean","sd","0.025quant",
                               "0.5quant","0.975quant","mode")

for (i in 1:2){
  df = quantized_data %>% filter(id == i) %>% select(response,time)
  preds = preds_kgr2 %>% filter(id == i) 
  df = cbind(df,preds)
  
  title = sprintf("Posterior Predictive Fits for Cluster %s",i)
  
  post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + 
    geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = `0.025quant`,ymax = `0.975quant`),alpha = 0.3) + geom_vline(xintercept = 54,linetype = "dashed",color = "blue",linewidth = 1.5) + ggtitle(title)
  print(post_pred_plot)
}
```

```{r}
preds_kgr %>% filter(id == 1) %>% select(sd) %>% unique()
preds_kgr2 %>% filter(id == 1) %>% select(sd) %>% unique()


lower1 = preds_kgr %>% filter(id == 1) %>% select(`0.025quant`) %>% unique()
lower2 = preds_kgr2 %>% filter(id == 1) %>% select(`0.025quant`) %>% unique()

upper1 = preds_kgr %>% filter(id == 1) %>% select(`0.975quant`) %>% unique()
upper2 = preds_kgr2 %>% filter(id == 1) %>% select(`0.975quant`) %>% unique()

upper1$`0.975quant` - lower1$`0.025quant` 
upper2$`0.975quant` - lower2$`0.025quant`
```


```{r}
preds_kgr %>% filter(id == 2) %>% select(sd) %>% unique()
preds_kgr2 %>% filter(id == 2) %>% select(sd) %>% unique()


lower1 = preds_kgr %>% filter(id == 2) %>% select(`0.025quant`) %>% unique()
lower2 = preds_kgr2 %>% filter(id == 2) %>% select(`0.025quant`) %>% unique()

upper1 = preds_kgr %>% filter(id == 2) %>% select(`0.975quant`) %>% unique()
upper2 = preds_kgr2 %>% filter(id == 2) %>% select(`0.975quant`) %>% unique()

upper1$`0.975quant` - lower1$`0.025quant` 
upper2$`0.975quant` - lower2$`0.025quant`
```

# Simulation study 2: can just load synthetic-study2-results.Rdata

```{r}
set.seed(101) #101 used in the paper 

#Make a synthetic adj matrix
row1 = c(0,0,0,0,0)
row2 = c(0,0,1,0,1)
row3 = c(0,1,0,1,0)
row4 = c(0,0,1,0,1)
row5 = c(0,1,0,1,0)

synth_adj = as.matrix(rbind(row1,row2,row3,row4,row5))

# install.packages("igraph")
# library(igraph)
# # Convert the adjacency matrix to a graph object
# g <- graph_from_adjacency_matrix(synth_adj, mode = "undirected")
# 
# # Assign custom labels to vertices
# V(g)$name <- c(1,2,3,4,5)
# 
# # Assign colors to vertices
# V(g)$color <- c("red", "cyan", "green", "yellow", "purple")
# 
# # Plot the graph with labeled vertices
# plot(g, vertex.label = V(g)$name, vertex.color = V(g)$color, vertex.size = 20)

#Calculate graph filter from adj matrix  
p = nrow(synth_adj)

#obtain graph Laplacian L
D = diag(p)
for (i in 1:p){
  d = sum(synth_adj[,i])
  D[i,i] = d
}

L = D - synth_adj

#eigendecomposition of L
Ldecomp = eigen(L)
U = as.matrix(Ldecomp$vectors)
Lambdas = Ldecomp$values

#test
#U %*% (diag(p)*Lambdas) %*% t(U)

#Function implementing cutoff tranform for eigenvalues 
cutoff.transform = function(lambdas,q){
  transformed = c()
  cutoff = quantile(lambdas,q)
  for (i in lambdas){
    if(i <= cutoff){
      transformed = c(transformed,1)
    }
    else{
      transformed = c(transformed,0)
    }
  }
  
  return(transformed)
}

#quantile(Lambdas,2/3)
transformed.L = cutoff.transform(Lambdas,2/3)
eta.L = diag(p)*transformed.L

#obtain graph filter
synth_H = U %*% eta.L %*% t(U)
synth_H

gfilter_weight = norm(synth_H^2,type = "F")
   
#Create a locally periodic time kernel w 2 periods 
t=1:300
rho_rbf = 50
rho_periodic1 = 1
rho_periodic2 = 1
sigma2 = 1

synth_K_time = matrix(NA,nrow = max(t), ncol = max(t))
  
for (i in 1:max(t)){
  for (j in 1:max(t)){
    # K_time[i,j] = exp(- (abs(i-j)^2) / (2*rho)) * sigma2
    
    # synth_K_time[i,j] = exp(- (abs(i-j)^2) / (2*rho_rbf)) * exp(- (2*sin(sum(abs(i-j))*3.14/12)^2)
    #                / (rho_periodic1)) * exp(- (2*sin(sum(abs(i-j))*3.14/6)^2)
    #                / (rho_periodic2)) * sigma2
    
        synth_K_time[i,j] = exp(- (abs(i-j)^2) / (2*rho_rbf)) * (exp(- (2*sin(sum(abs(i-j))*3.14/12)^2)
                   / (rho_periodic1)) + exp(- (2*sin(sum(abs(i-j))*3.14/6)^2)
                   / (rho_periodic2))) * sigma2
  }
}

K_time_weight = norm(synth_K_time,type = "F")

#Kronecker two components together to get cov matrix (make sure approx equal weight)
eigen_H = max(eigen(synth_H^2)$values)
eigen_K = max(eigen(synth_K_time)$values)

w = (1/eigen_K) / ((1/eigen_H) + (1/eigen_K))

synth_K_time2 = w*synth_K_time
synth_H2 = (1-w)*(synth_H^2)

K_time_weight = norm(synth_K_time2,type = "F")
gfilter_weight = norm(synth_H2,type = "F")

synth_covmatrix = kronecker(synth_K_time2,synth_H2)
  
#Generate synthetic mean for each year with two periods 
synth_means = c()

for (c in 1:5){
  cluster_mean = rep(0,300)
  A = rnorm(25,0,1)
  B = rnorm(25,0,1)
  
  A = rep(A,each=12)
  B = rep(B,each=12)
  
  for (i in 1:300){
    #get lambda for each year for each cluster
    cluster_mean[i] = A[i]*(sin(2*pi*i/12)) + B[i]*(sin(2*pi*i/6))  
  }
  
  synth_means = c(synth_means,cluster_mean)
}
  
#Simulate data from MVN
library(MASS)

synth_data = mvrnorm(1,synth_means,synth_covmatrix)

intercept1 = 1
intercept2 = 2
intercept3 = 3
intercept4 = 4
intercept5 = 5

intercepts = rep(c(intercept1,intercept2,intercept3,intercept4,intercept5),
                 each=300)

response = round(exp(synth_data + intercepts))
# response = synth_data

id = rep(c(1:5),each=300)
id2 = 1:(5*300)
time = rep(c(1:300),5)

synth_inla_data = data.frame(id,id2,response,time)

months = rep(c(1:12),25)
months = rep(months,5)
months = factor(months)
synth_inla_data = cbind(synth_inla_data,months)

#Add multiple intercept columns, one for each cluster 
Intercept1 = rep(c(1,NA,NA,NA,NA),300)
Intercept2 = rep(c(NA,1,NA,NA,NA),300)
Intercept3 = rep(c(NA,NA,1,NA,NA),300)
Intercept4 = rep(c(NA,NA,NA,1,NA),300)
Intercept5 = rep(c(NA,NA,NA,NA,1),300)

synth_inla_data = cbind(synth_inla_data,Intercept1,Intercept2,
                        Intercept3,Intercept4,Intercept5)
synth_inla_outsample_data = synth_inla_data

omit_idx = which(synth_inla_data$time > 240)
synth_inla_outsample_data$response[omit_idx] = NA
```

## Plot synthetic data

```{r}
detach("package:MASS", unload = TRUE)
library(patchwork)

true_mortality = synth_inla_data
true_mortality$time = as.numeric(true_mortality$time)

#Combine plots with library patchwork
true1 = true_mortality %>% filter(id == 1) %>% ggplot(aes(x=time,y=response)) + geom_line() + ggtitle("Cluster 1") + theme_classic()

true2 = true_mortality %>% filter(id == 2) %>% ggplot(aes(x=time,y=response)) + geom_line() + ggtitle("Cluster 2") + theme_classic()

true3 = true_mortality %>% filter(id == 3) %>% ggplot(aes(x=time,y=response)) + geom_line() + ggtitle("Cluster 3") + theme_classic()

true4 = true_mortality %>% filter(id == 4) %>% ggplot(aes(x=time,y=response)) + geom_line() + ggtitle("Cluster 4") + theme_classic()

true5 = true_mortality %>% filter(id == 5) %>% ggplot(aes(x=time,y=response)) + geom_line() + ggtitle("Cluster 5") + theme_classic()

true1 + true2 + true3 + true4 + true5






plot_list = list()

for (i in 1:5){
  title = sprintf("Cluster %s",i)
  
  true = true_mortality %>% filter(id == i) %>% ggplot(aes(x=time,y=response)) + geom_line() + ggtitle(title) +
    xlab("Month") + ylab("Intensity") + theme_classic(base_size = 14)
  
  plot_list[[i]] = true
}

combined = wrap_plots(plotlist = plot_list, ncol = 3)
combined

# save one combined figure
ggsave(
  filename = "synth2-ts-combined.png",
  plot = combined,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs/",
  width = 12,
  height = 8,
  dpi = 600
)
```

  
## Fit ref model 2

```{r}
poisson_pp_sampling = function(inla_fvs,n=100000){
  inla_fvs$y_ppmean = NA
  inla_fvs$y_pplower = NA
  inla_fvs$y_ppupper = NA
  
  for(i in 1:nrow(inla_fvs)){
    pp_samples = rpois(n,inla_fvs$mean[i])
    
    inla_fvs$y_ppmean[i] = mean(pp_samples)
    inla_fvs$y_pplower[i] = quantile(pp_samples,0.025)
    inla_fvs$y_ppupper[i] = quantile(pp_samples,0.975)
  }
    
  return(inla_fvs)  
}
```


```{r}
ref_formula2 = response ~ -1 + months + Intercept1 + Intercept2 + Intercept3 + Intercept4 + Intercept5  + 
    f(id, model = "bym", graph = synth_adj) #ID2 in formula results in error 

model = inla(formula = ref_formula2,family = "poisson",
             data = synth_inla_outsample_data,
              control.compute = list(dic=TRUE,waic=TRUE),
              control.inla = list(strategy = "laplace"),
              control.predictor = list(compute = TRUE, link = 1))

preds_model = model$summary.fitted.values
preds_model <- cbind(synth_inla_outsample_data$id, synth_inla_outsample_data$time, preds_model)
colnames(preds_model) <- c("id", "time", "mean", "sd", "0.025quant", "0.5quant", "0.975quant", "mode")
```

```{r}
plot_list = list()

for (i in 1:5){
  response = synth_inla_data %>% filter(id == i) %>% select(response)
  preds = preds_model %>% filter(id == i) 
  df = cbind(response,preds)
  df$mean = round(df$mean)
  
  df$y_ppmean = NA
  df$y_pplower = NA
  df$y_ppupper = NA
  
  for(j in 1:nrow(df)){
    pp_samples = rpois(100,df$mean[j])
    
    df$y_ppmean[j] = mean(pp_samples)
    df$y_pplower[j] = quantile(pp_samples,0.025)
    df$y_ppupper[j] = quantile(pp_samples,0.975)
  }
  
  title = sprintf("Cluster %s",i)
  
  post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = `0.025quant`,ymax = `0.975quant`),alpha = 0.3) + geom_vline(xintercept = 240,linetype = "dashed",color = "blue",linewidth = 1.5) + ggtitle(title) + xlab("Month") + ylab("Intensity") + theme_classic(base_size = 14)
  
  print(post_pred_plot)
  plot_list[[i]] = post_pred_plot
}

# combined = wrap_plots(plotlist = plot_list, ncol = 3)
# 
# # Save one combined figure
# ggsave(
#   filename = "synth2-ref-outsample-combined.png",
#   plot = combined,
#   path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
#   width = 15,
#   height = 13,
#   dpi = 600
# )
```

## Fit prop model 1

```{r,warning=FALSE}
rho_time_rbf = 50
rho_time_periodic = 1
sigma2_time = 1
  
#Calculating gram matrix K_time
K_time = time_kernel(time_span = length(unique(synth_inla_outsample_data$time)),
                      rho_rbf = rho_time_rbf,
                      rho_periodic = rho_time_periodic, sigma2 = sigma2_time)

#Calculate proposed kernel
covGP2 = kronecker(K_time,synth_H2)

#Need to ensure precision matrix is not computationally singular i.e det > 0
covGP_jittered = desingularize(covGP2,threshold = 1e-2,increment = 0.5)
covGP2 = covGP_jittered[[1]]

inv_covGP2 = solve(covGP2)

###Fit INLA model 
# kgr_formula1 = response ~ -1 + Intercept1 + Intercept2 + Intercept3 + Intercept4 + 
#   Intercept5 + f(id2,model = "generic0",Cmatrix = inv_covGP2)

kgr_formula1 = response ~ -1 + months + Intercept1 + Intercept2 + Intercept3 + Intercept4 + 
  Intercept5 + f(id2,model = "generic0",Cmatrix = inv_covGP2)

inla_model = inla(formula = kgr_formula1,family = "poisson",data = synth_inla_outsample_data,
                control.compute = list(dic=TRUE,waic=TRUE,
                                       return.marginals.predictor=TRUE),
                control.inla = list(strategy = "laplace"),
                control.predictor = list(compute = TRUE, link = 1))

inla_model$summary.fixed

preds_model2 = inla_model$summary.fitted.values
preds_model2 <- cbind(synth_inla_outsample_data$id, synth_inla_outsample_data$time, preds_model2)
colnames(preds_model2) <- c("id", "time", "mean", "sd", "0.025quant", "0.5quant", "0.975quant", "mode")
```

```{r}
plot_list = list()

for (i in 1:5){
  response = synth_inla_data %>% filter(id == i) %>% select(response)
  preds = preds_model2 %>% filter(id == i) 
  df = cbind(response,preds)
  df$mean = round(df$mean)
  
  df$y_ppmean = NA
  df$y_pplower = NA
  df$y_ppupper = NA

  for(j in 1:nrow(df)){
    pp_samples = rpois(100,df$mean[j])

    df$y_ppmean[j] = mean(pp_samples)
    df$y_pplower[j] = quantile(pp_samples,0.025)
    df$y_ppupper[j] = quantile(pp_samples,0.975)
  }
  
  title = sprintf("Cluster %s",i)
  
  post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = `0.025quant`,ymax = `0.975quant`),alpha = 0.3) + geom_vline(xintercept = 240,linetype = "dashed",color = "blue",linewidth = 1.5) + ggtitle(title) + xlab("Month") + ylab("Intensity") + theme_classic(base_size = 14)
  
  print(post_pred_plot)
  plot_list[[i]] = post_pred_plot
}

# combined = wrap_plots(plotlist = plot_list, ncol = 3)
# 
# # Save one combined figure
# ggsave(
#   filename = "synth2-kgr-outsample-combined.png",
#   plot = combined,
#   path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
#   width = 15,
#   height = 13,
#   dpi = 600
# )
```

## Sliding window forecast

Reference model 2: 

```{r,warning=FALSE,echo=FALSE,cache=TRUE}
synth_inla_data_ordered = synth_inla_data[order(synth_inla_data$time,decreasing=FALSE),]
rownames(synth_inla_data_ordered) = NULL
synth_starting_data = synth_inla_data_ordered[1:1000,] #252 for 36 months 
synth_starting_data$months = as.numeric(synth_starting_data$months)
synth_starting_data$id2 = c(1:nrow(synth_starting_data))
rownames(synth_starting_data) = NULL
synth_starting_data$lower = NA
synth_starting_data$upper = NA
synth_starting_data$y_pplower = NA
synth_starting_data$y_ppupper = NA

MAE = c()
MAPE = c()
RMSPE = c()

while(max(synth_starting_data$time) < 300){
  
  ###Attach df for next month with NAs in response
  end = nrow(synth_starting_data)
  id = c(1:5)
  id2 = (synth_starting_data$id2[end]+1):(synth_starting_data$id2[end]+5)
  response = rep(NA,5)
  lower = rep(NA,5)
  upper = rep(NA,5)
  y_pplower = rep(NA,5)
  y_ppupper = rep(NA,5)
  time = rep(synth_starting_data$time[end]+1,each=5)
  Intercept1 = c(1,NA,NA,NA,NA)
  Intercept2 = c(NA,1,NA,NA,NA)
  Intercept3 = c(NA,NA,1,NA,NA)
  Intercept4 = c(NA,NA,NA,1,NA)
  Intercept5 = c(NA,NA,NA,NA,1)
  
  if (synth_starting_data$months[end] == 12){
    months = rep(1,5)
  } else{
    value = synth_starting_data$months[end]
    months = rep((value+1),5)
  }
  
  new_data = data.frame(id,id2,response,time,months,Intercept1,Intercept2,Intercept3,
                      Intercept4,Intercept5,lower,upper,y_pplower,y_ppupper)
  synth_starting_data = rbind(synth_starting_data,new_data)
  synth_starting_data$months = factor(synth_starting_data$months)
  
  ###Fit reference model

  #Can set a fixed initial value for hyperprior if you want to fix hyperparameters
  # prec_prior <- list(prec = list(prior = "loggamma", param = c(0.01,0.01), inital = 2.771018, fixed=TRUE))
  
  ref_formula2 = response ~ -1 + months + Intercept1 + Intercept2 + Intercept3 + Intercept4 + 
    Intercept5 + f(id, model = "bym", graph = synth_adj) 
    
  ref_model2 = inla(ref_formula2,family = "poisson",data = synth_starting_data,
                  control.compute = list(dic=TRUE,waic=TRUE),
                  control.predictor = list(compute = TRUE, link = 1))
  
  ###Append ref model 2 predictions to starting data
  preds_ref_model2 = ref_model2$summary.fitted.values
  preds_ref_model2$mean = round(preds_ref_model2$mean)
  preds_ref_model2 = poisson_pp_sampling(preds_ref_model2,n=100)
  end2 = nrow(preds_ref_model2)
  
  pred_mean = preds_ref_model2$mean[(end2-4):end2]
  pred_lower = preds_ref_model2$`0.025quant`[(end2-4):end2]
  pred_upper = preds_ref_model2$`0.975quant`[(end2-4):end2]

  synth_starting_data$response[(end+1):(end+5)] = pred_mean
  synth_starting_data$lower[(end+1):(end+5)] = pred_lower
  synth_starting_data$upper[(end+1):(end+5)] = pred_upper

  pred_lower2 = preds_ref_model2$y_pplower[(end2-4):end2]
  pred_upper2 = preds_ref_model2$y_ppupper[(end2-4):end2]
  
  synth_starting_data$y_pplower[(end+1):(end+5)] = pred_lower2
  synth_starting_data$y_ppupper[(end+1):(end+5)] = pred_upper2
    
  # synth_starting_data$response = replace(synth_starting_data$response,which(synth_starting_data$response < 0),0)
  synth_starting_data$months = as.numeric(synth_starting_data$months)
  
  # ###Calculate performance metrics at each step (avg over all clusters)
  # est_lambda = rep(1,5)
  # 
  # for (c in 1:num_clus){
  # actual = inla_full_data %>% filter(id == c)  %>% data.frame()
  # m = unique(months)
  # 
  # actual_m = actual %>% filter(months == m) %>% select(response)
  # est_lambda[c] = mean(actual_m$response)
  # }
  # 
  # MAE = c(MAE,mean(abs(est_lambda - pred_data)))
  # MAPE = c(MAPE,mean(abs((est_lambda - pred_data)/est_lambda)))
  # RMSPE = c(RMSPE,sqrt(mean((est_lambda - pred_data)^2)))
}


###Have to calculate MASE for each time point separately
# MASE = c()
# m = 12
# 
# est_lambdas_df = rep(1,5)
# pred_test_df = rep(1,5)
# 
# for (j in 200:300){
#   for (c in 1:num_clus){
#     actual = synth_starting_data %>% filter(id == c)  %>% data.frame()
#     actual_m = actual %>% filter(months == m,time < j) %>% select(response)
#     est_lambda[c] = mean(actual_m$response)
#   }
#   
#   pred_test = synth_starting_data %>% filter(time == j) %>% select(response) %>% as.matrix() %>% c()
#   
#   pred_test_df = rbind(pred_test_df,pred_test)
#   est_lambdas_df = rbind(est_lambdas_df,est_lambda)
#   
#     if (m == 12){
#   m = 1
#   } else{
#   m = value+1
#   }
# }
# 
# est_lambdas_df = est_lambdas_df[-1,]
# pred_test_df = pred_test_df[-1,]
# 
# for (j in 2:nrow(pred_test_df)){
#   error = (abs(est_lambdas_df[j,] - pred_test_df[j,])) / (abs(est_lambdas_df[j,] - est_lambdas_df[(j-1),])) / (nrow(est_lambdas_df)-1)
#   MASE = c(MASE,mean(error))
# }
```

```{r}
plot_list = list()

for (i in 1:5){
  df = synth_inla_data %>% filter(id == i) %>% select(response,time)
  preds = synth_starting_data %>% filter(id == i) 
  df = cbind(df,preds)
  df = df[,-6]
  colnames(df)[5] = "mean"
  df$mean = round(df$mean)
  
  title = sprintf("Cluster %s",i)
  
  post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = lower,ymax = upper),alpha = 0.3) + geom_vline(xintercept = 200,linetype = "dashed",color = "blue",linewidth = 1.5) + ggtitle(title) + xlab("Month") + ylab("Intensity") + theme_classic(base_size = 14)
  print(post_pred_plot)
  
  plot_list[[i]] = post_pred_plot
}

combined = wrap_plots(plotlist = plot_list, ncol = 3)

# Save one combined figure
ggsave(
  filename = "synth2-ref-slidingforecast-combined.png",
  plot = combined,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
  width = 11,
  height = 9,
  dpi = 600
)
```

KGR-SKATER model: 

```{r,warning=FALSE,echo=FALSE,cache=TRUE}
rownames(synth_inla_data_ordered) = NULL
synth_starting_data2 = synth_inla_data_ordered[1:1000,] #1000 for 200 months 
synth_starting_data2$months = as.numeric(synth_starting_data2$months)
synth_starting_data2$id2 = c(1:nrow(synth_starting_data2))
rownames(synth_starting_data2) = NULL
synth_starting_data2$lower = NA
synth_starting_data2$upper = NA
synth_starting_data2$y_pplower = NA
synth_starting_data2$y_ppupper = NA

MAE = c()
MAPE = c()
RMSPE = c()

while(max(synth_starting_data2$time) < 300){
  
  ###Attach df for next month with NAs in response
  end = nrow(synth_starting_data2)
  id = c(1:5)
  id2 = (synth_starting_data2$id2[end]+1):(synth_starting_data2$id2[end]+5)
  response = rep(NA,5)
  lower = rep(NA,5)
  upper = rep(NA,5)
  y_pplower = rep(NA,5)
  y_ppupper = rep(NA,5)
  time = rep(synth_starting_data2$time[end]+1,each=5)
  Intercept1 = c(1,NA,NA,NA,NA)
  Intercept2 = c(NA,1,NA,NA,NA)
  Intercept3 = c(NA,NA,1,NA,NA)
  Intercept4 = c(NA,NA,NA,1,NA)
  Intercept5 = c(NA,NA,NA,NA,1)
  
  if (synth_starting_data2$months[end] == 12){
    months = rep(1,5)
  } else{
    value = synth_starting_data2$months[end]
    months = rep((value+1),5)
  }
  
  new_data = data.frame(id,id2,response,time,months,Intercept1,Intercept2,Intercept3,
                      Intercept4,Intercept5,lower,upper,y_pplower,y_ppupper)
  synth_starting_data2 = rbind(synth_starting_data2,new_data)
  synth_starting_data2$months = factor(synth_starting_data2$months)
  
  #Proposed model 1
  kgr_formula1 = response ~ -1 + months + Intercept1 + Intercept2 + Intercept3 + Intercept4 +
   Intercept5 + f(id2,model = "generic0",Cmatrix = inv_covGP2[c(synth_starting_data2$id2),c(synth_starting_data2$id2)])

  kgr_model1 = inla(kgr_formula1, data = synth_starting_data2, family = "poisson",
                    control.predictor = list(compute = TRUE, link = 1))

  preds_kgr_model = kgr_model1$summary.fitted.values
  
  ###Append KGR model predictions to starting data
  preds_kgr_model$mean = round(preds_kgr_model$mean)
  preds_kgr_model = poisson_pp_sampling(preds_kgr_model)
  end2 = nrow(preds_kgr_model)
  
  pred_mean = preds_kgr_model$mean[(end2-4):end2]
  pred_lower = preds_kgr_model$`0.025quant`[(end2-4):end2]
  pred_upper = preds_kgr_model$`0.975quant`[(end2-4):end2]

  synth_starting_data2$response[(end+1):(end+5)] = pred_mean
  synth_starting_data2$lower[(end+1):(end+5)] = pred_lower
  synth_starting_data2$upper[(end+1):(end+5)] = pred_upper

  pred_lower2 = preds_kgr_model$y_pplower[(end2-4):end2]
  pred_upper2 = preds_kgr_model$y_ppupper[(end2-4):end2]
  
  synth_starting_data2$y_pplower[(end+1):(end+5)] = pred_lower2
  synth_starting_data2$y_ppupper[(end+1):(end+5)] = pred_upper2
    
  synth_starting_data2$months = as.numeric(synth_starting_data2$months)
  
  # ###Calculate performance metrics at each step (avg over all clusters)
  # est_lambda = rep(1,5)
  # 
  # for (c in 1:num_clus){
  # actual = inla_full_data %>% filter(id == c)  %>% data.frame()
  # m = unique(months)
  # 
  # actual_m = actual %>% filter(months == m) %>% select(response)
  # est_lambda[c] = mean(actual_m$response)
  # }
  # 
  # MAE = c(MAE,mean(abs(est_lambda - pred_data)))
  # MAPE = c(MAPE,mean(abs((est_lambda - pred_data)/est_lambda)))
  # RMSPE = c(RMSPE,sqrt(mean((est_lambda - pred_data)^2)))
}


###Have to calculate MASE for each time point separately
# MASE = c()
# m = 12
# 
# est_lambdas_df = rep(1,5)
# pred_test_df = rep(1,5)
# 
# for (j in 200:300){
#   for (c in 1:num_clus){
#     actual = synth_starting_data2 %>% filter(id == c)  %>% data.frame()
#     actual_m = actual %>% filter(months == m,time < j) %>% select(response)
#     est_lambda[c] = mean(actual_m$response)
#   }
#   
#   pred_test = synth_starting_data2 %>% filter(time == j) %>% select(response) %>% as.matrix() %>% c()
#   
#   pred_test_df = rbind(pred_test_df,pred_test)
#   est_lambdas_df = rbind(est_lambdas_df,est_lambda)
#   
#     if (m == 12){
#   m = 1
#   } else{
#   m = value+1
#   }
# }
# 
# est_lambdas_df = est_lambdas_df[-1,]
# pred_test_df = pred_test_df[-1,]
# 
# for (j in 2:nrow(pred_test_df)){
#   error = (abs(est_lambdas_df[j,] - pred_test_df[j,])) / (abs(est_lambdas_df[j,] - est_lambdas_df[(j-1),])) / (nrow(est_lambdas_df)-1)
#   MASE = c(MASE,mean(error))
# }
```

```{r}
plot_list = list()

for (i in 1:5){
  df = synth_inla_data %>% filter(id == i) %>% select(response,time)
  preds = synth_starting_data2 %>% filter(id == i) 
  df = cbind(df,preds)
  df = df[,-6]
  colnames(df)[5] = "mean"
  df$mean = round(df$mean)
  
  title = sprintf("Cluster %s",i)
  
  post_pred_plot = df %>% ggplot(aes(x=time,y=response)) + geom_point() + geom_line(aes(y=mean),color = "red") + geom_ribbon(aes(ymin = lower,ymax = upper),alpha = 0.3) + geom_vline(xintercept = 200,linetype = "dashed",color = "blue",linewidth = 1.5) + ggtitle(title) + xlab("Month") + ylab("Intensity") + theme_classic(base_size = 14)
  
  print(post_pred_plot)
  plot_list[[i]] = post_pred_plot
}

combined = wrap_plots(plotlist = plot_list, ncol = 3)

# Save one combined figure
ggsave(
  filename = "synth2-kgr-slidingforecast-combined.png",
  plot = combined,
  path = "C:/Users/jeffr/Desktop/Spatiotemporal + Causal Inference/Wildfire Paper 1 Code/Paper1-images/plos1-figs",
  width = 11,
  height = 9,
  dpi = 600
)
```



